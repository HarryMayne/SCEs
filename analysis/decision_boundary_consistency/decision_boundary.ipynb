{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Boundary\n",
    "The main analysis notebook for this experiment. Note that the individual results are NOT included in the repo. We've only included the average over the 50 versions for space reasoning. The granular results can be generated using `main_log_probs.py`. This notebook combines the individual results into an average.\n",
    "\n",
    "NOTE: This code is legacy and likely won't work out of the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, gzip  \n",
    "import vllm\n",
    "import math\n",
    "import sys\n",
    "from collections import Counter\n",
    "sys.path.insert(0, \"../../src\")\n",
    "sys.path.insert(0, \"../..\")\n",
    "from config import REPO_ROOT\n",
    "import tqdm\n",
    "from utils import postprocessing\n",
    "import os\n",
    "import json\n",
    "import copy\n",
    "import numpy as np\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Dataset Name: folktexts_toy_minimal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1920/1920 [00:01<00:00, 1273.43it/s]\n",
      "100%|██████████| 1920/1920 [00:00<00:00, 501030.53it/s]\n",
      "100%|██████████| 1920/1920 [00:00<00:00, 519150.57it/s]\n",
      "100%|██████████| 1920/1920 [00:00<00:00, 643061.86it/s]\n",
      "100%|██████████| 1920/1920 [00:00<00:00, 595728.93it/s]\n",
      "100%|██████████| 1920/1920 [00:00<00:00, 507215.70it/s]\n",
      "100%|██████████| 1920/1920 [00:00<00:00, 500968.19it/s]\n",
      "100%|██████████| 1920/1920 [00:00<00:00, 477303.44it/s]\n",
      "100%|██████████| 1920/1920 [00:00<00:00, 514507.01it/s]\n",
      "100%|██████████| 1920/1920 [00:00<00:00, 490651.54it/s]\n",
      "100%|██████████| 1920/1920 [00:00<00:00, 525759.85it/s]\n"
     ]
    }
   ],
   "source": [
    "probs = []\n",
    "\n",
    "# load them in from the directory (need to generate t\n",
    "for i in range(1,11):\n",
    "    fname = REPO_ROOT / f\"analysis/decision_boundary_consistency/income_{i}.logprobs.pkl\"  \n",
    "    with gzip.open(fname, \"rb\") as f:    \n",
    "        probs.append(pickle.load(f))\n",
    "\n",
    "# extract full probs\n",
    "full_probs = {}\n",
    "\n",
    "# load the results and store in a dictionary... list\n",
    "results_list = []\n",
    "result = postprocessing(REPO_ROOT / 'results/income/llama3_3_70B.json', force=True, distance_metric=\"gower\", save=True, explicit_dataset=\"\")\n",
    "\n",
    "\n",
    "for ix, item in enumerate(probs):\n",
    "\n",
    "    probabilities = {}\n",
    "\n",
    "    for i in tqdm.tqdm(range(len(item))):\n",
    "        try:\n",
    "            above = math.exp(item[i][4][59907].logprob)\n",
    "        except:\n",
    "            above = 0\n",
    "        try:\n",
    "            below = math.exp(item[i][4][39314].logprob)\n",
    "        except:\n",
    "            below=0\n",
    "        probabilities.update({i:{\"Below\":below, \"Above\":above}})\n",
    "\n",
    "    full_probs.update({ix:probabilities})\n",
    "    results_list.append(copy.deepcopy(result))\n",
    "\n",
    "# iterate through each results and append answers\n",
    "updated_list = []\n",
    "for ix, result_ in enumerate(results_list):\n",
    "    for k,v in result_.items():\n",
    "        # if k==139:\n",
    "        #     print(float(full_probs[ix][k]['Below']))\n",
    "        v['Below'] = float(full_probs[ix][k]['Below'])\n",
    "        v['Above'] = float(full_probs[ix][k]['Above'])\n",
    "    updated_list.append(result_)\n",
    "\n",
    "averages_above = []\n",
    "averages_below = []\n",
    "# for all keys in 1 of the dicts\n",
    "for k,v in updated_list[0].items():\n",
    "    aboves = []\n",
    "    belows = []\n",
    "    for result in updated_list:\n",
    "        aboves.append(result[k]['Above'])\n",
    "        belows.append(result[k]['Below'])\n",
    "    averages_above.append(float(np.mean(aboves)))\n",
    "    averages_below.append(float(np.mean(belows)))\n",
    "\n",
    "    # get the averate\n",
    "\n",
    "    # set it to the average\n",
    "\n",
    "# set these valiues\n",
    "result_edited = postprocessing(REPO_ROOT / 'results/income/llama3_3_70B.json', force=True, distance_metric=\"gower\", save=True, explicit_dataset=\"\")\n",
    "\n",
    "for k,v in result_edited.items():\n",
    "    v['Above']=averages_above[k]\n",
    "    v['Below']=averages_below[k]\n",
    "\n",
    "# save to json\n",
    "with open(REPO_ROOT / \"results/income/average_two_ways.json\", \"w\") as f:\n",
    "    json.dump(result_edited, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(REPO_ROOT / \"results/income/llama3_3_70B\")\n",
    "n_files    = 50      \n",
    "n_examples = 1920        \n",
    "\n",
    "prediction2num = {'Below $50,000': 0, 'Above $50,000': 1}\n",
    "\n",
    "pred_matrix = np.zeros((n_examples, n_files), dtype=int)\n",
    "\n",
    "\n",
    "for col in range(n_files):\n",
    "    json_file = root / f\"income}.json\"\n",
    "    with open(json_file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for k, v in data.items():\n",
    "        idx = int(k)                     \n",
    "        if 0 <= idx < n_examples:        \n",
    "            pred_matrix[idx, col] = prediction2num[v[\"original_answer\"]]\n",
    "        else:\n",
    "            raise IndexError(\n",
    "                f\"{json_file}: index {idx} out of range 0–{n_examples-1}\"\n",
    "            )\n",
    "\n",
    "\n",
    "mean = np.mean(pred_matrix, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = REPO_ROOT / \"results/income/llama3_3_70B.json\"\n",
    "with open(json_path, \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
